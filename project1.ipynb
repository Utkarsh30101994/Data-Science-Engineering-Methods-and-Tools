{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd utkarsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary paackages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "seed = 4353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Musical_instruments_reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.lower()\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The train dataset contans {} rows and {} columns'.format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data.overall)\n",
    "plt.xlabel('Overall ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing numerical values with categorical values to reduce the classes to sentiments\n",
    "\n",
    "data['sentiment'] = data.overall.replace({\n",
    "    1:'negative',\n",
    "    2:'negative',\n",
    "    3:'neutral',\n",
    "    4:'positive',\n",
    "    5:'positive'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Train and Test datasets with only the product reviews (complete Review = reviewtext + summary)\n",
    "\n",
    "X_data = data['reviewtext'] + ' ' + data['summary']\n",
    "y_data = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the datatype from object to string\n",
    "\n",
    "X_data = X_data.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new dataframe\n",
    "\n",
    "X_data_df = pd.DataFrame(data=X_data)\n",
    "X_data_df.columns = ['review']\n",
    "X_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating functions for text processing\n",
    "\n",
    "string.punctuation\n",
    "def final(X_data_full):\n",
    "    \n",
    "    # function for removing punctuations\n",
    "    def remove_punct(X_data_func):\n",
    "        string1 = X_data_func.lower()\n",
    "        translation_table = dict.fromkeys(map(ord, string.punctuation),' ')\n",
    "        string2 = string1.translate(translation_table)\n",
    "        return string2\n",
    "    \n",
    "    X_data_full_clear_punct = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = remove_punct(X_data_full[i])\n",
    "        X_data_full_clear_punct.append(test_data)\n",
    "        \n",
    "    # function to remove stopwords\n",
    "    def remove_stopwords(X_data_func):\n",
    "        pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "        string2 = pattern.sub(' ', X_data_func)\n",
    "        return string2\n",
    "    \n",
    "    X_data_full_clear_stopwords = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = remove_stopwords(X_data_full[i])\n",
    "        X_data_full_clear_stopwords.append(test_data)\n",
    "        \n",
    "    # function for tokenizing\n",
    "    def tokenize_words(X_data_func):\n",
    "        words = nltk.word_tokenize(X_data_func)\n",
    "        return words\n",
    "    \n",
    "    X_data_full_tokenized_words = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = tokenize_words(X_data_full[i])\n",
    "        X_data_full_tokenized_words.append(test_data)\n",
    "        \n",
    "    # function for lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize_words(X_data_func):\n",
    "        words = lemmatizer.lemmatize(X_data_func)\n",
    "        return words\n",
    "    \n",
    "    X_data_full_lemmatized_words = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = lemmatize_words(X_data_full[i])\n",
    "        X_data_full_lemmatized_words.append(test_data)\n",
    "        \n",
    "    # creating the bag of words model\n",
    "    cv = CountVectorizer(max_features=1000)\n",
    "    X_data_full_vector = cv.fit_transform(X_data_full_lemmatized_words).toarray()\n",
    "    \n",
    "    \n",
    "    tfidf = TfidfTransformer()\n",
    "    X_data_full_tfidf = tfidf.fit_transform(X_data_full_vector).toarray()\n",
    "    \n",
    "    return X_data_full_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the function\n",
    "\n",
    "data_X = final(X_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, y_data, test_size=0.25, random_state= seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiation, fitting and prediction\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, y_train)\n",
    "predictions = MNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "MNB_f1 = round(f1_score(y_test, predictions, average='weighted'), 3)\n",
    "MNB_accuracy = round((accuracy_score(y_test, predictions)*100),2)\n",
    "\n",
    "print(\"Accuracy : \" , MNB_accuracy , \" %\")\n",
    "print(\"f1_score : \" , MNB_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiation, fitting and predictions\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators= 10, random_state= seed)\n",
    "rfc.fit(X_train, y_train)\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "rfc_f1 = round(f1_score(y_test, predictions, average= 'weighted'), 3)\n",
    "rfc_accuracy = round((accuracy_score(y_test, predictions) * 100), 2)\n",
    "\n",
    "print(\"Accuracy : \" , rfc_accuracy , \" %\")\n",
    "print(\"f1_score : \" , rfc_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('Reviews.csv')\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns = data1.columns.str.lower()\n",
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The train dataset contans {} rows and {} columns'.format(data1.shape[0], data1.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data1.score)\n",
    "plt.xlabel('Score ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing numerical values with categorical values to reduce the classes to sentiments\n",
    "\n",
    "data1['sentiment'] = data1.score.replace({\n",
    "    1:'negative',\n",
    "    2:'negative',\n",
    "    3:'neutral',\n",
    "    4:'positive',\n",
    "    5:'positive'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Train and Test datasets with only the product reviews (complete Review = reviewtext + summary)\n",
    "\n",
    "X_data = data1['text'] + ' ' + data1['summary']\n",
    "y_data = data1['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the datatype from object to string\n",
    "\n",
    "X_data = X_data.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new dataframe\n",
    "\n",
    "X_data_df = pd.DataFrame(data=X_data)\n",
    "X_data_df.columns = ['reviews']\n",
    "X_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating functions for text processing\n",
    "\n",
    "string.punctuation\n",
    "def final(X_data_full):\n",
    "    \n",
    "    # function for removing punctuations\n",
    "    def remove_punct(X_data_func):\n",
    "        string1 = X_data_func.lower()\n",
    "        translation_table = dict.fromkeys(map(ord, string.punctuation),' ')\n",
    "        string2 = string1.translate(translation_table)\n",
    "        return string2\n",
    "    \n",
    "    X_data_full_clear_punct = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = remove_punct(X_data_full[i])\n",
    "        X_data_full_clear_punct.append(test_data)\n",
    "        \n",
    "    # function to remove stopwords\n",
    "    def remove_stopwords(X_data_func):\n",
    "        pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
    "        string2 = pattern.sub(' ', X_data_func)\n",
    "        return string2\n",
    "    \n",
    "    X_data_full_clear_stopwords = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = remove_stopwords(X_data_full[i])\n",
    "        X_data_full_clear_stopwords.append(test_data)\n",
    "        \n",
    "    # function for tokenizing\n",
    "    def tokenize_words(X_data_func):\n",
    "        words = nltk.word_tokenize(X_data_func)\n",
    "        return words\n",
    "    \n",
    "    X_data_full_tokenized_words = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = tokenize_words(X_data_full[i])\n",
    "        X_data_full_tokenized_words.append(test_data)\n",
    "        \n",
    "    # function for lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize_words(X_data_func):\n",
    "        words = lemmatizer.lemmatize(X_data_func)\n",
    "        return words\n",
    "    \n",
    "    X_data_full_lemmatized_words = []\n",
    "    for i in range(len(X_data_full)):\n",
    "        test_data = lemmatize_words(X_data_full[i])\n",
    "        X_data_full_lemmatized_words.append(test_data)\n",
    "        \n",
    "    # creating the bag of words model\n",
    "    cv = CountVectorizer(max_features=1000)\n",
    "    X_data_full_vector = cv.fit_transform(X_data_full_lemmatized_words).toarray()\n",
    "    \n",
    "    \n",
    "    tfidf = TfidfTransformer()\n",
    "    X_data_full_tfidf = tfidf.fit_transform(X_data_full_vector).toarray()\n",
    "    \n",
    "    return X_data_full_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the function\n",
    "\n",
    "data_X = final(X_data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X, y_data, test_size=0.25, random_state= seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiation, fitting and prediction\n",
    "\n",
    "MNB = MultinomialNB()\n",
    "MNB.fit(X_train, y_train)\n",
    "predictions = MNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "MNB_f1 = round(f1_score(y_test, predictions, average='weighted'), 3)\n",
    "MNB_accuracy = round((accuracy_score(y_test, predictions)*100),2)\n",
    "\n",
    "print(\"Accuracy : \" , MNB_accuracy , \" %\")\n",
    "print(\"f1_score : \" , MNB_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiation, fitting and predictions\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(n_estimators= 10, random_state= seed)\n",
    "rfc.fit(X_train, y_train)\n",
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "rfc_f1 = round(f1_score(y_test, predictions, average= 'weighted'), 3)\n",
    "rfc_accuracy = round((accuracy_score(y_test, predictions) * 100), 2)\n",
    "\n",
    "print(\"Accuracy : \" , rfc_accuracy , \" %\")\n",
    "print(\"f1_score : \" , rfc_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiation and fitting\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "svc = SVC(random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using KFold cross validation technique\n",
    "kf=  KFold(n_splits=5, random_state=seed)\n",
    "\n",
    "# Hyperparametric tuning using grid search\n",
    "param_grid = [{'kernel':['rbf'],\n",
    "              'gamma':[1e-3, 1e-4],\n",
    "              'C':[1, 10, 100, 1000]},\n",
    "             {'kernel':['linear'],\n",
    "             'C':[1, 10, 100, 1000]}]\n",
    "\n",
    "grid = GridSearchCV(estimator=svc, param_grid=param_grid, scoring='accuracy', cv=kf)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print('Estimator: ', grid.best_estimator_)\n",
    "print('Best params : \\n', grid.best_params_)\n",
    "print('Output Classes: ', grid.classes_)\n",
    "print('Training Accuracy: ', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "\n",
    "predictions = grid.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "svc_f1 = round(f1_score(y_test, predictions, average='weighted'), 3)\n",
    "svc_accuracy = round((accuracy_score(y_test, predictions)*100), 2)\n",
    "\n",
    "print(\"Accuracy : \" , svc_accuracy , \" %\")\n",
    "print(\"f1_score : \" , svc_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
